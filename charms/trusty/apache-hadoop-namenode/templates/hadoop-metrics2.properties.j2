#
#   Licensed to the Apache Software Foundation (ASF) under one or more
#   contributor license agreements.  See the NOTICE file distributed with
#   this work for additional information regarding copyright ownership.
#   The ASF licenses this file to You under the Apache License, Version 2.0
#   (the "License"); you may not use this file except in compliance with
#   the License.  You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#

# syntax: [prefix].[source|sink].[instance].[options]
# See javadoc of package-info.java for org.apache.hadoop.metrics2 for details

*.sink.file.class=org.apache.hadoop.metrics2.sink.FileSink
# default sampling period, in seconds
*.period=10

# Defining sink for Ganglia 3.1
{{ ganglia_sink_str }}

# Default polling period for GangliaSink
*.sink.ganglia.period=10

# default for supportsparse is false
*.sink.ganglia.supportsparse=true

# Directing output to ganglia servers

*.sink.ganglia.slope=jvm.metrics.gcCount=zero,jvm.metrics.memHeapUsedM=both
*.sink.ganglia.dmax=jvm.metrics.threadsBlocked=70,jvm.metrics.memHeapUsedM=40

namenode.sink.ganglia.servers={{ ganglia_host }}:8649
datanode.sink.ganglia.servers={{ ganglia_host }}:8649
jobtracker.sink.ganglia.servers={{ ganglia_host }}:8649
tasktracker.sink.ganglia.servers={{ ganglia_host }}:8649
maptask.sink.ganglia.servers={{ ganglia_host }}:8649
reducetask.sink.ganglia.servers={{ ganglia_host }}:8649
resourcemanager.sink.ganglia.servers={{ ganglia_host }}:8649
nodemanager.sink.ganglia.servers={{ ganglia_host }}:8649
historyserver.sink.ganglia.servers={{ ganglia_host }}:8649
journalnode.sink.ganglia.servers={{ ganglia_host }}:8649
resourcemanager.sink.ganglia.tagsForPrefix.yarn=Queue

# The namen de-metrics. ut will contain metrics from all context
#namenode.sink.file.filename=namenode-metrics.out
# Specifying a special sampling period for namenode:
#namenode.sink.*.period=8

#datanode.sink.file.filename=datanode-metrics.out

# the following example split metrics of different
# context to different sinks (in this case files)
#jobtracker.sink.file_jvm.context=jvm
#jobtracker.sink.file_jvm.filename=jobtracker-jvm-metrics.out
#jobtracker.sink.file_mapred.context=mapred
#jobtracker.sink.file_mapred.filename=jobtracker-mapred-metrics.out

#tasktracker.sink.file.filename=tasktracker-metrics.out

#maptask.sink.file.filename=maptask-metrics.out

#reducetask.sink.file.filename=reducetask-metrics.out
